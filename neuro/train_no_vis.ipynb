{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "import sys\n",
    "# if \"/Users/ludo/Desktop/animalai/animalai/animalai_train\" not in sys.path:\n",
    "#     sys.path.insert(0, \"/Users/ludo/Desktop/animalai/animalai/animalai_train\")\n",
    "# if  \"/Users/ludo/Desktop/animalai/animalai/animalai\" not in sys.path:\n",
    "#     sys.path.insert(1, \"/Users/ludo/Desktop/animalai/animalai/animalai\")\n",
    "# if  \"/Users/ludo/Desktop/animalai/ml-agents/ml-agents\" not in sys.path:\n",
    "#     sys.path.insert(0, \"/Users/ludo/Desktop/animalai/ml-agents/ml-agents\")\n",
    "\n",
    "from animalai.envs.environment import AnimalAIEnvironment\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "from mlagents.trainers.trainer_util import load_config;\n",
    "from animalai_train.run_options_aai import RunOptionsAAI;\n",
    "from animalai_train.run_training_aai import run_training_aai;\n",
    "\n",
    "trainer_config_path = \"configurations/training_configurations/no_vis_config.yaml\"\n",
    "\n",
    "with open(trainer_config_path) as f:\n",
    "    print(f.read())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "environment_path = \"../env/env18\"\n",
    "curriculum_path = \"configurations/curriculum4\"\n",
    "run_id = \"octx4\"\n",
    "base_port = 5004\n",
    "number_of_environments = 1\n",
    "number_of_arenas_per_environment = 1\n",
    "\n",
    "args = RunOptionsAAI(\n",
    "    trainer_config=load_config(trainer_config_path),\n",
    "    env_path=environment_path,\n",
    "    run_id=run_id,\n",
    "    base_port=base_port,\n",
    "    num_envs=number_of_environments,\n",
    "    curriculum_config=curriculum_path,\n",
    "    n_arenas_per_env=number_of_arenas_per_environment,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATE\n",
    "from animalai.envs.arena_config import ArenaConfig\n",
    "\n",
    "args = RunOptionsAAI(\n",
    "    trainer_config=load_config(trainer_config_path),\n",
    "    env_path=environment_path,\n",
    "    run_id=run_id,\n",
    "    base_port=base_port+3,\n",
    "    load_model=True,\n",
    "    train_model=False,\n",
    "#     arena_config=ArenaConfig(\"configurations/curriculum4/20.yml\")\n",
    "    arena_config=ArenaConfig('../competition_configurations/5-10-1.yml')\n",
    ")\n",
    "run_training_aai(0, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TRAIN\n",
    "\n",
    "# logging.getLogger('tensorflow').disabled = True\n",
    "\n",
    "# logs_dir = \"summaries/\"\n",
    "# os.makedirs(logs_dir, exist_ok=True)\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir {logs_dir}\n",
    "\n",
    "run_training_aai(0, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/Users/ludo/Desktop/animalai/animalai\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path = sys.path[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir(\"/Users/ludo/Desktop/animalai/animalai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del person.things[:]\n",
    "person.things.extend([thing1, thing2, ..])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "tempfile.gettempdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from clyngor import ASP, solve\n",
    "ans = ASP(\"\"\"\n",
    "\n",
    "present(a).\n",
    "present(X):- visible(X).\n",
    "obstructs(X,Y) :- present(X), present(Y), visible(X), not visible(Y).\n",
    "initiate(explore(X,Y)) :- visible(X), obstructs(X,Y).\n",
    "initiate(interact(a)):- visible(a).\n",
    "\n",
    "check(visible(Y)):- initiate(explore(X,Y)).\n",
    "check(time(150)):- initiate(explore(X,Y)).\n",
    "\n",
    "check(time):- initiate(interact(a)).\n",
    "check(reached(a)):- initiate(interact(a)).\n",
    "terminate(explore(X,Y)):-explore(X,Y), check(time).\n",
    "terminate(explore(X,Y)):-explore(X,Y), check(visible(Y)).\n",
    "terminate(interact(a)):-interact(a), check(time).\n",
    "terminate(interact(a)):-interact(a), check(reached(a)).\n",
    "\t\"\"\")\n",
    "answer_sets = list(list(ans)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(answer_sets)\n",
    "# Fetch initiate and checks\n",
    "kw = ['initiate', 'check', 'terminate']\n",
    "def split_predicate(x):\n",
    "    predicate = x.split('(')[0]\n",
    "    if '(' in x:\n",
    "        var = x.split('(')[1].split(')')[0]\n",
    "    else:\n",
    "        var = '-'\n",
    "    return [predicate, var]\n",
    "filtered_answer_sets = {\n",
    "    k: [split_predicate(i[1][0]) for i in answer_sets if i[0] ==k] for k in kw\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_answer_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mlagents.trainers.ppo.trainer import PPOTrainer\n",
    "cf = load_config(trainer_config_path)['AnimalAI']\n",
    "cf['model_path'] = './models/octx7'\n",
    "cf['summary_path'] = './summaries'\n",
    "\n",
    "ppt = PPOTrainer(\n",
    "    brain_name='bra',\n",
    "    reward_buff_cap=1,\n",
    "    trainer_parameters=cf,\n",
    "    training=False, \n",
    "    load=True, \n",
    "    seed=1,\n",
    "    run_id=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppt.export_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "#     tf.compat.v1.saved_model.load(sess,\n",
    "#         export_dir='./models/octx8/AnimalAI/raw', tags=None\n",
    "#     )\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    print(\"load graph\")\n",
    "    with tf.io.gfile.GFile(GRAPH_PB_PATH,'rb') as f:\n",
    "        graph_def = tf.compat.v1.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "    sess.graph.as_default()\n",
    "    tf.import_graph_def(graph_def, name='')\n",
    "    graph_nodes=[n for n in graph_def.node]\n",
    "    names = []\n",
    "    for t in graph_nodes:\n",
    "        names.append(t.name)\n",
    "    print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mlagents.tf_utils import tf\n",
    "# tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "def load_pb(path_to_pb):\n",
    "    with tf.gfile.GFile(path_to_pb, \"rb\") as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def, name='')\n",
    "        return graph\n",
    "GRAPH_PB_PATH = './models/blindgotox9/AnimalAI/frozen_graph_def.pb'\n",
    "graph = load_pb(GRAPH_PB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlagents import tf_utils\n",
    "# graph = tf.Graph()\n",
    "sess = tf.Session(\n",
    "            config=tf_utils.generate_session_config(), graph=graph\n",
    "        )\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "sess.run(tf.local_variables_initializer())\n",
    "sess.run(init)\n",
    "#     saver = tf.train.Saver(max_to_keep=5)\n",
    "#     ckpt = tf.train.get_checkpoint_state('./models/blindgotox9/AnimalAI/')\n",
    "#     saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "\n",
    "\n",
    "# with tf.compat.v1.Session(graph=graph) as sess:\n",
    "log_probs = graph.get_tensor_by_name('action:0')\n",
    "action = graph.get_tensor_by_name('policy_1/concat:0')\n",
    "b_size = graph.get_tensor_by_name('batch_size:0')\n",
    "out_dict = {'action':action, 'log_probs':log_probs}\n",
    "action_masks = graph.get_tensor_by_name('action_masks:0')\n",
    "feed_dict = {\n",
    "#     tf.placeholder(\n",
    "#             shape=None, dtype=tf.int32, name=\"batch_size\"\n",
    "#         ): 1,\n",
    "#     tf.placeholder(\n",
    "#             shape=None, dtype=tf.int32, name=\"sequence_length\"\n",
    "#         ):1,\n",
    "    graph.get_tensor_by_name('vector_observation:0'):np.array(\n",
    "        [[ 0.        ,  0.        , -0.29925328, -0.18826045, -0.40039593,\n",
    "     0.        ,  0.        , -0.92760783,  0.13117751, -0.56681085]]),\n",
    "    action_masks:np.array([[1, 1, 1, 1, 1, 1]])\n",
    "}\n",
    "s_len = graph.get_tensor_by_name('sequence_length:0')\n",
    "input_node = graph.get_tensor_by_name('vector_observation:0')\n",
    "model_result = sess.run(\n",
    "    list(out_dict.values()),\n",
    "    feed_dict =feed_dict)\n",
    "\n",
    "model_result.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.compat.v1.Session(graph=graph) as sess:\n",
    "    output_node = graph.get_tensor_by_name('policy_1/concat_2:0')\n",
    "    input_node = graph.get_tensor_by_name('vector_observation:0')\n",
    "    action_masks = graph.get_tensor_by_name('action_masks:0')\n",
    "    model_result = sess.run(\n",
    "        output_node,\n",
    "        feed_dict ={\n",
    "        input_node : np.array(\n",
    "            [[ 0.        ,  0.        , -0.13292775,  0.13525054,  0.3048224 ,\n",
    "         0.        ,  0.        , -0.16626114,  0.1663723 ,  0.28901497]]),\n",
    "             action_masks: np.array([[1,1,1,1,1,1]])})\n",
    "print(model_result[0, :3])\n",
    "print(model_result[0, 3:])\n",
    "model_result\n",
    "# .flatten().argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [n.name for n in tf.get_default_graph().as_graph_def().node]\n",
    "tensors_per_node = [node.values() for node in graph.get_operations()]\n",
    "tensor_names = [tensor for tensors in tensors_per_node for tensor in tensors]\n",
    "tensor_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FEED DICT {<tf.Tensor 'batch_size:0' shape=<unknown> dtype=int32>: 1,\n",
    "           <tf.Tensor 'sequence_length:0' shape=<unknown> dtype=int32>: 1}\n",
    "FEED DICT2 {<tf.Tensor 'batch_size:0' shape=<unknown> dtype=int32>: 1,\n",
    "            <tf.Tensor 'sequence_length:0' shape=<unknown> dtype=int32>: 1,\n",
    "            <tf.Tensor 'vector_observation:0' shape=(?, 10) dtype=float32>: array([[ 0.        ,  0.        , -0.29925328, -0.18826045, -0.40039593,\n",
    "         0.        ,  0.        , -0.92760783,  0.13117751, -0.56681085]],\n",
    "      dtype=float32),\n",
    "            <tf.Tensor 'action_masks:0' shape=(?, 6) dtype=float32>: np.array([[1, 1, 1, 1, 1, 1]])}\n",
    "out_dict {'action': <tf.Tensor 'policy_1/concat:0' shape=(?, 2) dtype=int64>,\n",
    "          'log_probs': <tf.Tensor 'action:0' shape=(?, 6) dtype=float32>, 'entropy': <tf.Tensor 'policy_1/Sum_2:0' shape=(?,) dtype=float32>}\n",
    "Network out [array([[2, 1]]), array([[-1.5424949e+01, -1.5424949e+01, -1.1920929e-07, -1.5390121e+01,\n",
    "        -1.1920929e-07, -1.5424949e+01]], dtype=float32), array([1.3276538e-05], dtype=float32)]\n",
    "run out {'action': array([[2, 1]]),\n",
    "         'log_probs': array([[-1.5424949e+01, -1.5424949e+01, -1.1920929e-07, -1.5390121e+01,\n",
    "        -1.1920929e-07, -1.5424949e+01]], dtype=float32), 'entropy': array([1.3276538e-05], dtype=float32)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.array([1,2,3])\n",
    "x.resize(4)\n",
    "np.matrix(x).reshape(4,1).resize(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros(10)[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "animalaienv",
   "language": "python",
   "name": "animalaienv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
